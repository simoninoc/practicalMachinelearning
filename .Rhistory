sample(x. replace = T)
?sample
sample(x, replace = T)
sample(x, 3, replace = T)
training = spam[inTrain,]#Define a trainning data set
model = train(type~, data = training, method = "glm")
model = train(type~., data = training, method = "glm")
?train
warnings()
model
str(model)
model$modelInfo
model$finalModel
library(ggplot2)
library(caret)
library(ISLR)
install.packages("ISLR")
library(ISLR)
data(Wage)
summary(Wage)
inTrain = createDataPartition(Wage$wage, p = 0.7, list = F)
training = Wage[inTrain,]
testing = Wage[-inTrain,]
featurePlot(x = training[,c("age", "education","jobclass")], y = training$wage, plot = "pairs")
?featurePlot
featurePlot(x = training[,c("age", "education","jobclass")], y = training$wage, plot = "box")
featurePlot(x = training[,c("age", "education","jobclass")], y = training$wage, plot = ""strip")
featurePlot(x = training[,c("age", "education","jobclass")], y = training$wage, plot = "strip")
featurePlot(x = training[,c("age", "education","jobclass")], y = training$wage, plot = "paris")
featurePlot(x = training[,c("age", "education","jobclass")], y = training$wage, plot = "pairs")
featurePlot(x = training[,c("age", "education","jobclass")], y = training$wage, plot = "pairs")
?preProcess
library(Caret)
library(caret)
?preProcess
library(kernlab)
data(spam)
inTrain = createDataPartition(y = spam$type, p = 0.75, list = F)
training = spam[inTrain,]
testing = spam[-inTrain,]
training[,-58]
testvector = c(1,2,3,4,5)
testvector(-3)
testvector[-3]
standardize = preProcess(training, method = c("center", scale))
training[,58]
standardize = preProcess(training[,-58], method = c("center", scale))
standardize = preProcess(training[,-58], method = c("center", "scale"))
capave = predict(standardize,training[,-58])$capitalAve
capave
model = train(type~.,data = training, preProcess = c("center","scale"), method = "glm")
model
M <- abs(cor(training[,-58]))
M
which(M>0.8,arr.ind = T)
diag(M) = 0
which(M>0.8,arr.ind = T)
smallspam = spam[,c(32,34)]
principal_component = prcomp(smallspam)
head(smallspam)
smallspam
sum(smallpam)
sum(smallspam)
plot(smallspam[1],smallspam[2])
smallspam[!smallspam[1]==0,1]
smallspam[!smallspam[1]==0,]
plot(smallspam[1],smallspam[2])
plot(smallspam[2]~smallspam[1])
head(smallspam)
plot(num857~num415, data = smallspam)
plot(num415~num857, data = smallspam)
plot(principal_component[,1],principal_component[,2])
principal_component = prcomp(smallspam)
plot(principal_component[,1],principal_component[,2])
principal_component
?principal_component
?prcomp
str(prcomp)
principal_component$x
plot(principal_component$x[,1],principal_component$x[,2])
library(AppliedPredictiveModeling)
install.packages("AppliedPredictiveModeling")
library(AppliedPredictiveModeling)
library(caret)
data(AlzheimerDisease)
data(concrete)
library(caret)
set.seed(975)
inTrain = createDataPartition(mixtures$CompressiveStrength, p = 3/4)[[1]]
training = mixtures[ inTrain,]
testing = mixtures[-inTrain,]
concrete
head(concrete)
mixtrues
mixtures
head(mixture)
head(mixtures)
inTrain
createDataPartition(mixtures$CompressiveStrength, p = 3/4)
head(mixtures)
featurePlot(x = mixtures[,-CompressiveStrength], y = mixtures[,CompressiveStrength],plot = "pairs")
featurePlot(x = mixtures[,-"CompressiveStrength"], y = mixtures[,"CompressiveStrength"],plot = "pairs")
featurePlot(x = mixtures[,-7], y = mixtures[,7],plot = "pairs")
library(Hmisc)
splitOn <- cut2(training$Age, g = 4)
splitOn <- mapvalues(splitOn,
from = levels(factor(splitOn)),
to = c("red", "blue", "yellow", "green"))
# automatically includes index of samples
plot(training$CompressiveStrength, col = splitOn)
?cut2
library(AppliedPredictiveModeling)
data(concrete)
library(caret)
set.seed(975)
inTrain = createDataPartition(mixtures$CompressiveStrength, p = 3/4)[[1]]
training = mixtures[ inTrain,]
testing = mixtures[-inTrain,]
head(training)
hist(training$Superplasticizer)
hist(log(training$Superplasticizer+1))
library(caret)
library(AppliedPredictiveModeling)
set.seed(3433)
data(AlzheimerDisease)
adData = data.frame(diagnosis,predictors)
inTrain = createDataPartition(adData$diagnosis, p = 3/4)[[1]]
training = adData[ inTrain,]
testing = adData[-inTrain,]
?preProcess
data(AlzheimerDisease)
adData = data.frame(diagnosis,predictors)
inTrain = createDataPartition(adData$diagnosis, p = 3/4)[[1]]
training = adData[ inTrain,]
testing = adData[-inTrain,]
ss <- testing[,grep('^IL', x = names(testing) )]
model1 <- train(ss, testing$diagnosis, method='glm')
model2 <- preProcess(ss, method='pca', thresh = 0.8, outcome = testing$diagnosis)
model1
model2 <- preProcess(ss, method='pca', thresh = 0.8, outcome = testing$diagnosis)
model2
library(Hmisc)
?cut2
library(Hmisc)
cutWage = cut2(training$wage, g = 3)#g specify number of intervals to be cutted to
cutWage = cut2(train$wage, g = 3)#g specify number of intervals to be cutted to
train
training
inTrain = createDataPartition(Wage$wage, p = 0.7, list = F)
inTrain = createDataPartition(Wage$wage, p = 0.7, list = F)
training = Wage[inTrain,]
testing = Wage[-inTrain,]
library(ggplot2)
library(caret)
library(ISLR)
data(Wage)
summary(Wage)
inTrain = createDataPartition(Wage$wage, p = 0.7, list = F)
training = Wage[inTrain,]
testing = Wage[-inTrain,]
library(Hmisc)
cutWage = cut2(train$wage, g = 3)#g specify number of intervals to be cutted to
cutWage = cut2(training$wage, g = 3)#g specify number of intervals to be cutted to
training
head(cutWage)
names(training)
p1 = qplot(cutWage, age , data = training, fill = cutWage, geom = c("boxplot"))
```
p1 = qplot(cutWage, age , data = training, fill = cutWage, geom = c("boxplot"))
p1
class(cutWage)
table(cutWage, training$jobclass)
?table
table(cutWage)
t1 = table(cutWage, training$jobclass) #table function can take one or more factors
prop.table(t1, margin = 1)
qplot(wage, color = education, data = training, geom = "density")
install.packages(c("Rcpp", "httpuv", "shiny"))
install.packages(c("Rcpp", "httpuv", "shiny"))
install.packages(c("Rcpp", "httpuv", "shiny"))
library(kernlab)
data(spam)
inTrain = createDataPartition(y = spam$type, p = 0.75, list = F)
training = spam[inTrain,]
testing = spam[-inTrain,]
library(caret)
inTrain = createDataPartition(y = spam$type, p = 0.75, list = F)
training = spam[inTrain,]
testing = spam[-inTrain,]
head(training[,-58])
standardize = preProcess(training[,-58], method = c("center", "scale"))
class(standardize)
capave = predict(standardize,training[,-58])$capitalAve
capave
dimj(training)
dim(training)
rbinom(10)
rbinom(n = 10,size = 5,prob = 0.05)
?rbinom
rbinom(n = 10,size = 1,prob = 0.5)
rbinom(n = 10,size = 100,prob = 0.5)
rbinom(n = 10,size = 0,prob = 0.5)
pcaSpam = preProcess(x = spam, method = "pca",pcaComp = 2)
pcaSpam = preProcess(x = spam[,-58], method = "pca",pcaComp = 2)
spamPC = predict(pcaSpam, spam[,-58])
plot(spamPC[,1],spamPC[,2],col = typeColor)
spam$type
plot(spamPC[,1],spamPC[,2],col = type)
spam$typeColor
plot(spamPC[,1],spamPC[,2])
qplot(spamPC[,1],spamPC[,2],color = type)
qplot(spamPC[,1],spamPC[,2])
qplot(spamPC[,1],spamPC[,2],color = type, data = spam)
data(concrete)
library(caret)
set.seed(975)
inTrain = createDataPartition(mixtures$CompressiveStrength, p = 3/4)[[1]]
training = mixtures[ inTrain,]
testing = mixtures[-inTrain,]
library(caret)
data(concrete)
library(AppliedPredictiveModeling)
data(concrete)
set.seed(975)
inTrain = createDataPartition(mixtures$CompressiveStrength, p = 3/4)[[1]]
training = mixtures[ inTrain,]
testing = mixtures[-inTrain,]
hist(training)
hist(training$SuperPlasticizer)
names(training)
hist(training$Superplasticizer)
length(training[training$Superplasticizer==0,"Superplasticizer"])
log(0)
set.seed(3433)
data(AlzheimerDisease)
adData = data.frame(diagnosis,predictors)
inTrain = createDataPartition(adData$diagnosis, p = 3/4)[[1]]
training = adData[ inTrain,]
testing = adData[-inTrain,]
preObj = preProcess(x = training,method = "pca")
head(training)
length(names(training))
preObj = preProcess(x = training[-131],method = "pca")
allvars = names(training)
allvars
library(stringr)
varnames = names(train)# Get all variables
grepl(pattern = "IL",x = varnames)
grepl(pattern = "^IL",x = varnames,ignore.case = T)
grep(pattern = "^IL",x = varnames,ignore.case = T)
grepl("IL","IL_123")
grepl("IL",c("IL_123",123)
)
varnames
varnames = names(train)# Get all variables
varnames
varnames = names(training)# Get all variables
grep(pattern = "^IL",x = varnames,ignore.case = T)
indicator = grepl(pattern = "^IL",x = varnames,ignore.case = T)
var_subset = varnames[indicator]
var_subset
preObj = preProcess(x = training[var_subset],method = "pca")
PC = predict(preObj, training)
PC = predict(preObj, training[var_subset])
length(PC)
Genoset
training$Geno
preObj = preProcess(x = training[var_subset],method = "pca",thresh = 0.9)
PC = predict(preObj, training[var_subset])
length(PC)
training$diag
train(training$diagnosis~PC,method = "glm")
train(training$diagnosis~.,data = training[var_subset],method = "glm")
train(training$diagnosis~.,data = PC, method = "glm")
preObj = preProcess(x = training[var_subset],method = "pca",thresh = 0.8)
PC = predict(preObj, training[var_subset])
train(training$diagnosis~.,data = training[var_subset],method = "glm")
train(training$diagnosis~.,data = PC, method = "glm")
data(AlzheimerDisease)
adData = data.frame(diagnosis,predictors)
inTrain = createDataPartition(adData$diagnosis, p = 3/4)[[1]]
training = adData[ inTrain,]
testing = adData[-inTrain,]
varnames = names(training)# Get all variables
indicator = grepl(pattern = "^IL",x = varnames,ignore.case = T)
var_subset = varnames[indicator]
preObj = preProcess(x = training[var_subset],method = "pca",thresh = 0.8)
PC = predict(preObj, training[var_subset])
train(training$diagnosis~.,data = training[var_subset],method = "glm")
train(training$diagnosis~.,data = PC, method = "glm")
training
head(training)
nonPCA = train(training$diagnosis~.,data = training[var_subset],method = "glm")
PCA = train(training$diagnosis~.,data = PC, method = "glm")
nonPCA_Accuracy = confusionMatrix(data = predict(nonPCA,testing),reference = testing$diagnosis )
nonPCA_Accuracy
PCA_Accuracy = confusionMatrix(data = predict(PCA,testing),reference = testing$diagnosis)
PCA = train(training$diagnosis~.,data = PC, method = "glm")
PCA_Accuracy = confusionMatrix(data = predict(PCA,testing),reference = testing$diagnosis)
PCA
predict(PCA,testing)
PC = predict(preObj, training[var_subset])
PCA = train(training$diagnosis~.,data = PC, method = "glm")
predict(PCA,testing)
PCA = train(training$diagnosis~.,data = training[var_subset], method = "glm",preProcess = "pca",
Control = trainControl(preProcOptions = list(thresh = 0.8)))
PCA =  train(training$diagnosis ~ ., method = "glm", data = training,
preProcess = "pca",
Control = trainControl(preProcOptions = list(thresh = 0.8)))
PCA_Accuracy = confusionMatrix(data = predict(PCA,testing),reference = testing$diagnosis)
model1 = train(training$diagnosis~.,data = training[var_subset],method = "glm")
train(training$diagnosis ~ ., method = "glm", data = training[var_subset],
preProcess = "pca",
Control = trainControl(preProcOptions = list(thresh = 0.8)))
preObj = preProcess(x = training[-"diagnosis"],method = "pca",thresh = 0.8)
length(var_subset)
onfusionMatrix(data = predict(nonPCA,testing),reference = testing$diagnosis)
confusionMatrix(data = predict(nonPCA,testing),reference = testing$diagnosis)
preObj = preProcess(x = training[var_subset],method = "pca",thresh = 0.8)
PC = predict(preObj, training[var_subset])
head(PC)
model2 =  train(training$diagnosis~ ., method = "glm", data = PC)
PC_testing = predict(preProcess(testing[var_subset],method = "pca",thresh = 0.8),testing[var_subset])
PCA_Accuracy = confusionMatrix(data = predict(PCA,PCA_testing),reference = testing$diagnosis)
PC_testing = predict(preProcess(testing[var_subset],method = "pca",thresh = 0.8),testing[var_subset])
PCA_testing = predict(preProcess(testing[var_subset],method = "pca",thresh = 0.8),testing[var_subset])
PCA_Accuracy = confusionMatrix(data = predict(PCA,PCA_testing),reference = testing$diagnosis)
PCA_testing = predict(preObj,testing[var_subset])
PCA_Accuracy = confusionMatrix(data = predict(PCA,PCA_testing),reference = testing$diagnosis)
OCA_Accuracy
PCA_Accuracy
names(predictor_subset)
training = read.csv("./Project/pml-training.csv")
testing = read.csv("./Project/pml-training.csv")
valid_predictor_position = which(NAperCol==0)
predictors_subset = training[valid_predictor_position]
NAmark = apply(X = training,MARGIN = 2,FUN = is.na)
NAperCol = colSums(NAmark)
valid_predictor_position = which(NAperCol==0)
predictors_subset = training[valid_predictor_position]
predictors_subset = predictors_subset[-(1:7)]
apply(predictors_subset,MARGIN = 2,FUN = class)
head(predictors_subset)
predictor_subsets[4]
predictors_subset[4]
predictors_subset[5]
head(predictors_subset[5])
predictors_subset[5][1]
training[12]
head(is.na(training[12]))
class(training[12])
training[12][1]
training[12][1][1]
test = training[12]
training[12]==0
training[12]==NULL
training[12]==NAN
training[12]==NaN
head(training[12]==Null)
head(training[12]==NULL)
head(training[12]==NA)
head(training[8]==NA)
head(training[9]==NA)
head(training[22]==NA)
head(training)
head(training[8])
head(training[8]==1.41)
head(training[8]==NA)
head(is.na(training[8]))
head(predictors_subset[5])
is.na(predictors_subset[5])
head(is.na(predictors_subset[5]))
head(predictors_subset[5]>0)
class(predictors_subset)
class(predictors_subset[5])
class(training[8])
head(is.numeric(predictors_subset[5]))
head(as.numeric(predictors_subset[5]))
NAmark = apply(X = training,MARGIN = 2,FUN = is.na)
NAmark
head(training)
NAperCol = colSums(NAmark)
NAperCol
apply(training,2,class)
numeric = apply(predictors_subset,2,as.numeric)
warnings()
predictors_subset = predictors_subset[-86]
predictors_subset = apply(predictors_subset,2,as.numeric)
NACheck = apply(predictors_subset,2,is.na)
NAperCol = colSums(NACheck)
NAperCol
valid_position = which(NAperCol==0)
predictors_subset = predictors_subset[valid_position]
predictors_subset
NAmark = apply(X = training,MARGIN = 2,FUN = is.na)
NAperCol = colSums(NAmark)
valid_predictor_position = which(NAperCol==0)
predictors_subset = training[valid_predictor_position]
predictors_subset = predictors_subset[-(1:7)]
predictors_subset = predictors_subset[-86]
apply(predictors_subset,2,as.numeric)
predictors_subset = apply(predictors_subset,2,as.numeric)#Convert to numeric vector
predictors_subset = is.data.frame(predictors_subset)
predictors_subset = predictors_subset[valid_position]
valid_position
predictors_subset
training = read.csv("./Project/pml-training.csv")
testing = read.csv("./Project/pml-training.csv")
NAmark = apply(X = training,MARGIN = 2,FUN = is.na)
NAperCol = colSums(NAmark)
predictors_subset = predictors_subset[-(1:7)]
predictors_subset = predictors_subset[-86]
copy = predictors subset
copy = predictors_subset
predictors_subset = apply(predictors_subset,2,as.numeric)#Convert to numeric vector
NAmark = apply(X = training,MARGIN = 2,FUN = is.na)
NAperCol = colSums(NAmark)
valid_predictor_position = which(NAperCol==0)
predictors_subset = training[valid_predictor_position]
predictors_subset = predictors_subset[-(1:7)]
predictors_subset = predictors_subset[-86]
copy = predictors_subset
predictors_subset = apply(predictors_subset,2,as.numeric)#Convert to numeric vector
NACheck = apply(predictors_subset,2,is.na) #Return logic indicators of each observation
NAperCol = colSums(NACheck)#Count NAs of each columns
valid_position = which(NAperCol==0)# Mark down valid columns that without NAs.
predictors_subset = is.data.frame(predictors_subset)
predictors_subset = copy
predictors_subset = apply(predictors_subset,2,as.numeric)#Convert to numeric vector
NACheck = apply(predictors_subset,2,is.na) #Return logic indicators of each observation
NAperCol = colSums(NACheck)#Count NAs of each columns
valid_position = which(NAperCol==0)# Mark down valid columns that without NAs.
predictors_subset = as.data.frame(predictors_subset)
predictors_subset = predictors_subset[valid_position]
head(predictors_subset)
treeModel = train(training$classe~.,data = predictors_subset,method = "rpart")
library(caret)
treeModel = train(training$classe~.,data = predictors_subset,method = "rpart")
training_predict = predict(treeModel,predicors_subset)
training_predict = predict(treeModel,predictors_subset)
summary(treeModel)
treeModel$finalModel
library(rattle)
install.packages("rattle")
library(rattle)
fancyRpartPlot(treeModel$finalModel)
install.packages("rpart.plot")
fancyRpartPlot(treeModel$finalModel)
predictions = predict(treeModel,testing)
confusionMatrix(data = testing$classe,reference = predictions)
str(treeModel)
treeModel$result
confusionMatrix(data = training$classe, reference = predict(treeModel,predictors_subset))
predictions = predict(treeModel,testing)
confusionMatrix(data = testing$classe,reference = predictions)
testing = read.csv("./Project/pml-testing.csv")
predictions = predict(treeModel,testing)
confusionMatrix(data = testing$classe,reference = predictions)
testing
predictions
alltrain = read.csv("./project/pml-training.csv")
inTrain = createDataPartition(y = training,p = 0.6,list = F)
inTrain = createDataPartition(y = training$classe,p = 0.6,list = F)
training = alltrain[inTrain]
training = alltrain[inTrain,]
testing = alltrain[-inTrain,]
NAmark = apply(X = training,MARGIN = 2,FUN = is.na)
NAperCol = colSums(NAmark)
valid_predictor_position = which(NAperCol==0)
predictors_subset = training[valid_predictor_position]
predictors_subset = predictors_subset[-(1:7)]
predictors_subset = predictors_subset[-86]
NACheck = apply(predictors_subset,2,is.na) #Return logic indicators of each observation
NAperCol = colSums(NACheck)#Count NAs of each columns
valid_position = which(NAperCol==0)# Mark down valid columns that without NAs.
predictors_subset = as.data.frame(predictors_subset)
predictors_subset = predictors_subset[valid_position]
head(predictors_subset)
predictors_subset = apply(predictors_subset,2,as.numeric)#Convert to numeric vector
NACheck = apply(predictors_subset,2,is.na) #Return logic indicators of each observation
NAperCol = colSums(NACheck)#Count NAs of each columns
valid_position = which(NAperCol==0)# Mark down valid columns that without NAs.
predictors_subset = as.data.frame(predictors_subset)
predictors_subset = predictors_subset[valid_position]
treeModel = train(training$classe~.,data = predictors_subset,method = "rpart")
treeModel$finalModel
library(rattle)
fancyRpartPlot(treeModel$finalModel)
treeModel = train(training$classe~.,data = predictors_subset,method = "rpart")
treeModel$finalModel
library(rattle)
fancyRpartPlot(treeModel$finalModel)
confusionMatrix(data = training$classe, reference = predict(treeModel,predictors_subset))
confusionMatrix(data = testing$classe, reference = predict(treeModel,testing))
forestModel = train(training$classe~.,data = predictors_subset,method = "rf",trControl = trainControl(method = "cv",number = 4))
confusionMatrix(data = testing$classe,reference = predict(forestModel,testing))
external_test = read.csv("./project/pml-testing.csv")
predictions = predict(forestModel,external_test)
predictions
pml_write_files = function(x){
n = length(x)
for(i in 1:n){
filename = paste0("problem_id_",i,".txt")
write.table(x[i],file=filename,quote=FALSE,row.names=FALSE,col.names=FALSE)
}
}
pml_write_files(predictions)
inTrain = createDataPartition(y = training$classe,p = 0.6,list = F)
?knit2html
knit2html("courseProject_ZhuoruLin.rmd")
library(knitr)
knit2html("courseProject_ZhuoruLin.rmd")
